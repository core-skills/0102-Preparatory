{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Skills Prerequisite - Intro to Pandas\n",
    "\n",
    "This lesson is adapted from the [Data Carpentry Ecology lesson](http://www.datacarpentry.org/python-ecology-lesson/)\n",
    "\n",
    "\n",
    "## How to use a Jupyter Notebook\n",
    "\n",
    "https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "\n",
    "https://jupyterlab.readthedocs.io/en/stable/user/notebook.html\n",
    "\n",
    "- The file autosaves\n",
    "- You run a cell with **shift + enter** or using the run button in the tool bar\n",
    "- If you run a cell with **option + enter** it will also create a new cell below\n",
    "- See *Help > Keyboard Shortcuts* or the *Cheatsheet* for more info\n",
    "\n",
    "\n",
    "- The notebook has different type of cells: Code and Markdown are most commonly used\n",
    "- **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with # -> code after this will not be executed\n",
    "- **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Pandas DataFrames in Python\n",
    "\n",
    "## Starting in the same spot\n",
    "\n",
    "To help the lesson run smoothly, let's ensure everyone is in the same directory.\n",
    "This should help us avoid path and file name issues. At this time please\n",
    "navigate to the workshop directory. If you working in IPython Notebook be sure\n",
    "that you start your notebook in the workshop directory.\n",
    "\n",
    "A quick aside that there are Python libraries like [OS\n",
    "Library](https://docs.python.org/3/library/os.html) that can work with our\n",
    "directory structure, however, that is not our focus today.\n",
    "\n",
    "If you need to change your directory ```import os``` and use ```os.chdir```\n",
    "\n",
    "## Our Data \n",
    "\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data\n",
    "from Ernst et al\n",
    "[Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm)\n",
    "\n",
    "We will be using files from the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).\n",
    "This section will use the `surveys.csv` file which can be found in /data/python/python_data\n",
    "\n",
    "We are studying the species and weight of animals caught in plots in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot             | ID of a particular plot            |\n",
    "| species          | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| wgt              | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:\n",
    "\n",
    "```\n",
    "record_id,month,day,year,plot,species,sex,wgt\n",
    "1,7,16,1977,2,NA,M,\n",
    "2,7,16,1977,3,NA,M,\n",
    "3,7,16,1977,2,DM,F,\n",
    "```\n",
    "\n",
    "## About Libraries\n",
    "\n",
    "A library in Python contains a set of tools (called functions) that perform\n",
    "tasks on our data. Importing a library is like getting a piece of lab equipment\n",
    "out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used or called to perform many tasks.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default. We have to\n",
    "add an `import` statement to our code in order to use library functions. To import\n",
    "a library, we use the syntax `import libraryName`. If we want to give the\n",
    "library a nickname to shorten the command, we can add `as nickNameHere`.  An\n",
    "example of importing the pandas library using the common nickname `pd` is below.\n",
    "\n",
    "You only need to load a library once during your session. You can load the library when needed\n",
    "or you can load all necessary libraries at the beginning of your script. \n",
    "This is good practice, especially for the readability of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "# Run this cell and when it complete restart the kernel for this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas in Python\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the\n",
    "[Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas). The\n",
    "Pandas library provides data structures, produces high quality plots with\n",
    "[matplotlib](http://matplotlib.org/) and integrates nicely with other libraries\n",
    "that use [NumPy](http://www.numpy.org/) (which is another Python library) arrays.\n",
    "\n",
    "A handy **Pandas cheathsheet** can be found [here](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n",
    "Each time we call a function that's in a library, we use the syntax\n",
    "`LibraryName.FunctionName`. Adding the library name with a `.` before the\n",
    "function name tells Python where to find the function. In the example above, we\n",
    "have imported Pandas as `pd`. This means we don't have to type out `pandas` each\n",
    "time we call a Pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you need to change your directory\n",
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# check your version, we need v0.19 or higher\n",
    "pd.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading CSV Data Using Pandas\n",
    "\n",
    "We will begin by locating and reading our survey data which are in CSV format.\n",
    "We can use Pandas' `read_csv` function to pull the file directly into a\n",
    "[DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe).\n",
    "\n",
    "## So What's a DataFrame?\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different\n",
    "types (including characters, integers, floating point values, factors and more)\n",
    "in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in\n",
    "R. A DataFrame always has an index (0-based). An index refers to the position of \n",
    "an element in the data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that pd.read_csv is used because we imported pandas as pd\n",
    "pd.read_csv(\"surveys.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were 33,549 rows parsed. Each row has 9\n",
    "columns. The first column is the index of the DataFrame. The index is used to\n",
    "identify the position of the data, but it is not an actual column of the DataFrame. \n",
    "It looks like  the `read_csv` function in Pandas  read our file properly. However, \n",
    "we haven't saved any data to memory so we can work with it.We need to assign the \n",
    "DataFrame to a variable. Remember that a variable is a name for a value, such as `x`, \n",
    "or  `data`. We can create a new  object with a variable name by assigning a value to it using `=`.\n",
    "\n",
    "Let's call the imported survey data `surveys_df`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df = ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not\n",
    "produce any output on the screen. We can print the value of the `surveys_df`\n",
    "object by typing its name into the Python command prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Our Species Survey Data\n",
    "\n",
    "Now we can start manipulating our data. First, let's check the data type of the\n",
    "data stored in `surveys_df` using the `type` method. The `type` method and\n",
    "`__class__` attribute tell us that `surveys_df` is `<class 'pandas.core.frame.DataFrame'>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(surveys_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also look at the .__class__ attribute\n",
    "surveys_df.__class__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also enter `surveys_df.dtypes` at our prompt to view the data type for each\n",
    "column in our DataFrame. `int64` represents numeric integer values - `int64` cells\n",
    "can not store decimals. `object` represents strings (letters and numbers). `float64`\n",
    "represents numbers with decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas and base Python use slightly different names for data types. More on this\n",
    "is in the table below:\n",
    "\n",
    "| Pandas Type | Native Python Type | Description |\n",
    "|-------------|--------------------|-------------|\n",
    "| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs(see below), pandas will default to float64, in case your missing value has a decimal. |\n",
    "| datetime64, timedelta[ns] | N/A (but see the [datetime](http://doc.python.org/2/library/datetime.html) module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring DataFrames in Python\n",
    "\n",
    "There are multiple methods that can be used to access and summarise the data\n",
    "stored in DataFrames. Let's try out a few. Note that we call the method by using\n",
    "the object name followed by . and the method name. So `surveys_df.columns` provides an index\n",
    "of all of the column names in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Rows and Columns\n",
    "\n",
    "\n",
    "In pandas you can use several ways to **select a specific column**:\n",
    "- square brackets `[]` \n",
    "- a `.` and the column name\n",
    "\n",
    "For example, we can select all of data from a column named `species` from the `surveys_df`\n",
    "DataFrame by name:\n",
    "\n",
    "```python\n",
    "surveys_df['species']\n",
    "# this syntax, calling the column as an attribute, gives you the same output\n",
    "surveys_df.species\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using double square brackets `[[]]` we can pass a list of column names too by listing the names we want.\n",
    "Lets look at both the `record_id` and the `species` columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create an new object that contains the data as follows:\n",
    "\n",
    "```python\n",
    "# create an object named surveys_species that only contains the `species_id` column\n",
    "surveys_species = surveys_df['species']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If a column name is not contained in the DataFrame, an exception\n",
    "(error) will be raised.\n",
    "\n",
    "```python\n",
    "surveys_df['speciess']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "Try out the methods below to see what they return.\n",
    "\n",
    "1. `surveys_df.columns`.\n",
    "2. `surveys_df.head()`. Also, what does `surveys_df.head(15)` do?\n",
    "3. `surveys_df.tail()`.\n",
    "4. `surveys_df.shape`. Take note of the output of the shape method. What format does it return the shape of the DataFrame in?\n",
    "\n",
    "HINT: [More on tuples, here](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Converting between different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the types of data we have in our dataframe\n",
    "surveys_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the record_id field from an integer to a float\n",
    "my_col = surveys_df['record_id']\n",
    "my_col = my_col.astype('float64')\n",
    "surveys_df['record_id'] = my_col\n",
    "# alternatively we can do all the above in one line by chaining the commands together\n",
    "# surveys_df['record_id'] = surveys_df['record_id'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we try to convert `wgt` values to integers (`int64`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this throws a value error: `ValueError: Cannot convert NA to\n",
    "integer`. If we look at the `weight` column in the surveys data we notice that\n",
    "there are NaN (**N**ot **a** **N**umber) values. *NaN* values are undefined\n",
    "values that cannot be represented mathematically. Pandas, for example, will read\n",
    "an empty cell in a CSV or Excel sheet as a NaN. NaNs have some desirable\n",
    "properties: if we were to average the `weight` column without replacing our NaNs,\n",
    "Python would know to skip over those cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the wgt column and look for nan values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look at the mean of this column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: older pandas version do not know how to handle NaN, please update to v0.19 or higher_\n",
    "\n",
    "Check your pandas version using `pd.__version__`, if you need to update open a bash shell\n",
    "and type ```conda update pandas```.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Values - NaN\n",
    "\n",
    "Dealing with missing data values is always a challenge. It's sometimes hard to\n",
    "know why values are missing - was it because of a data entry error? Or data that\n",
    "someone was unable to collect? Should the value be 0? We need to know how\n",
    "missing values are represented in the dataset in order to make good decisions.\n",
    "If we're lucky, we have some metadata that will tell us more about how null\n",
    "values were handled.\n",
    "\n",
    "For instance, in some disciplines, like Remote Sensing, missing data values are\n",
    "often defined as -9999. Having a bunch of -9999 values in your data could really\n",
    "alter numeric calculations. Often in spreadsheets, cells are left empty where no\n",
    "data are available. Pandas will, by default, replace those missing values with\n",
    "NaN. However it is good practice to get in the habit of intentionally marking\n",
    "cells that have no data, with a no data value! That way there are no questions\n",
    "in the future when you (or someone else) explores your data.\n",
    "\n",
    "### Where Are the NaN's?\n",
    "\n",
    "Let's explore the NaN values in our data a bit further. \n",
    "First, let's figure out **how many rows contain NaN values for weight**. \n",
    "We can do this by identifying how many rows have a NULL value (`.isnull`) or by counting the number of rows that have a meaningful value (e.g., wgt>0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using >0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace all NaN values with zeroes using the `.fillna()` method (after\n",
    "making a copy of the data so we don't lose our work).\n",
    "\n",
    "However, NaN and 0 yield different analysis results. The mean value when NaN\n",
    "values are replaced with 0 is different from when NaN values are simply thrown\n",
    "out or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "# We make a copy of the data frame\n",
    "df1 = surveys_df.copy()\n",
    "df1['wgt'] = ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mean, how does it differ from before?\n",
    "print(surveys_df['wgt'].mean())\n",
    "print(df1['wgt'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill NaN values with any value that we chose. The code below fills all\n",
    "NaN values with a mean for all weight values.\n",
    "\n",
    "```python\n",
    " df1['wgt'] = surveys_df['wgt'].fillna(surveys_df['wgt'].mean())\n",
    "```\n",
    "\n",
    "We could also chose to create a subset of our data, only keeping rows that do\n",
    "not contain NaN values, using `.dropna()` method.\n",
    "\n",
    "**The point is to make conscious decisions about how to manage missing data.** \n",
    "This is where we think about how our data will be used and how these values will\n",
    "impact the scientific conclusions made from the data.\n",
    "\n",
    "Python gives us all of the tools that we need to account for these issues. We\n",
    "just need to be cautious about how the decisions that we make impact scientific\n",
    "results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['wgt'] = ?\n",
    "print(surveys_df['wgt'].mean())\n",
    "print(df1['wgt'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating summary statistics for a Pandas DataFrame\n",
    "\n",
    "We've read our data into Python. Next, let's perform some quick summary\n",
    "statistics to learn more about the data that we're working with. We might want\n",
    "to know how many animals were collected in each plot, or how many of each\n",
    "species were caught. We can perform summary stats quickly using groups. But\n",
    "first we need to figure out what we want to group by.\n",
    "\n",
    "---\n",
    "\n",
    "Let's find out how many unique plot IDs and species we have in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of the column names\n",
    "surveys_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unique plot ID's  and species found in the surveys data\n",
    "plot_names = ?\n",
    "species = ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of the list\n",
    "print(f'There are: {?} unique plots in the data')\n",
    "print(f'There are: {?} unique species in the data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single line solution\n",
    "print(f\"There are: {?} unique plots in the data\")\n",
    "print(f\"There are: {?} unique species in the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The Pandas function `describe` will return descriptive stats including: mean,\n",
    "median, max, min, std and count for a particular column in the data. Pandas'\n",
    "`describe` function will only return summary values for columns containing\n",
    "numeric data.\n",
    "We can calculate basic statistics for all records in a single column using the\n",
    "syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the `wgt` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:\n",
    "\n",
    "```python\n",
    "surveys_df['wgt'].min()\n",
    "surveys_df['wgt'].max()\n",
    "surveys_df['wgt'].mean()\n",
    "surveys_df['wgt'].std()\n",
    "surveys_df['wgt'].count()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Basic Math Functions\n",
    "\n",
    "If we wanted to, we could perform math on an entire column of our data. For\n",
    "example let's multiply all weight values by 2. A more practical use of this might\n",
    "be to normalize the data according to a mean, area, or some other value\n",
    "calculated from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply all weight values by 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups in Pandas\n",
    "\n",
    "We often want to calculate summary statistics grouped by subsets or attributes\n",
    "within fields of our data, for example we might want to know what the summary stats look like split by sex.\n",
    "We can use Pandas' `.groupby` method, which creates a groupby DataFrame on which we can perform other pandas methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the df by sex\n",
    "by_sex = ?\n",
    "\n",
    "# summary statistics for this new df\n",
    "by_sex.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the mean for each numeric column by sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby` command is powerful in that it allows us to quickly generate\n",
    "summary stats, not just for one group but several.\n",
    "\n",
    "For example, we might want to calculate the average\n",
    "weight of all individuals per plot:\n",
    "\n",
    "```python\n",
    "surveys_df.groupby('plot')['wgt'].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average weight of individuals in each plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we might want to know how many males and females we have for each species:\n",
    "\n",
    "```python\n",
    "surveys_df.groupby(['species','sex'])['record_id'].count()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of each sex per species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "1. Calculate the average weight for each species per plot\n",
    "2. Calculate the average weight for each sex of each species per plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.groupby(['plot', 'species'])['wgt'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.groupby(['plot', 'species', 'sex'])['wgt'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick & Easy Plotting Data Using Pandas\n",
    "\n",
    "We can plot our summary stats using Pandas, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure figures appear inline in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# plot year vs wgt\n",
    "surveys_df.plot(x='year', y='wgt', kind='scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a quick bar chart\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at how many animals were captured in each plot:\n",
    "total_count = surveys_df.groupby('plot')['record_id'].nunique()\n",
    "\n",
    "# let's plot that too, default is a line plot\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activities\n",
    "\n",
    "1. Create a plot of average weight across all species per plot. x-axis = plot, y-axis = wgt\n",
    "2. Create the same plot, but with average weight for each sex per plot. Hint, you will need to `unstack` when plotting. x-axis = plot, y-axis = wgt, different lines for each sex.\n",
    "3. Create a trend plot of the average weight per plot over time. x-axis = year, y-axis = wgt, different lines for each plot. (For the first 5 plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# group by plot and calculate mean wgt\n",
    "avrg_wgt = ?\n",
    "\n",
    "# let's plot, you should see x-axis -> plot, y-axis -> wgt\n",
    "avrg_wgt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# group by plot and sex, then calculate mean wgt\n",
    "avrg_wgt = ?\n",
    "\n",
    "# let's plot, you should see x-axis -> plot, y-axis -> wgt, different lines for sex\n",
    "# you need to use the .unstack() method before the .plot() for this to work\n",
    "avrg_wgt.unstack().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see what unstack actually does\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# group by year and plot, then calculate mean wgt\n",
    "wgt_by_time = ?\n",
    "\n",
    "# let's plot, you should see x-axis -> year, y-axis -> wgt, different lines for plot\n",
    "# you need to use the .unstack() method before the .plot() for this to work\n",
    "wgt_by_time.unstack().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing & Slicing in Python\n",
    "\n",
    "We often want to work with subsets of a **DataFrame** object. There are\n",
    "different ways to accomplish this including: using labels (ie, column headings - as used previously),\n",
    "numeric ranges or specific x,y index locations.\n",
    "\n",
    "## Extracting Range based Subsets: Slicing\n",
    "\n",
    "**REMINDER**: Python Uses 0-based Indexing\n",
    "\n",
    "Let's remind ourselves that Python uses 0-based\n",
    "indexing. This means that the first element in an object is located at position\n",
    "0. This is different from other tools like R and Matlab that index elements\n",
    "within objects starting at 1.\n",
    "\n",
    "\n",
    "![indexing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-indexing.png)\n",
    "\n",
    "![slicing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-slicing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a list of numbers:\n",
    "a = [1,2,3,4,5]\n",
    "```\n",
    "\n",
    "1. What value does the code below return?\n",
    "        a[0]\n",
    "2. How about this:\n",
    "        a[5]\n",
    "3. Or this?\n",
    "        a[len(a)]\n",
    "4. In the example above, calling `a[5]` returns an error. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows in Python\n",
    "\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a\n",
    "DataFrame. To slice out a set of rows, you use the following syntax:\n",
    "`data[start:stop]`. When slicing in pandas the start bound is included in the\n",
    "output. The stop bound is one step BEYOND the row you want to select. So if you\n",
    "want to select rows 0, 1 and 2 your code would look like this:\n",
    "\n",
    "```python\n",
    "# select rows 0,1,2 (but not 3)\n",
    "surveys_df[0:3]\n",
    "```\n",
    "\n",
    "The stop bound in Python is different from what you might be used to in\n",
    "languages like Matlab and R.\n",
    "\n",
    "```python\n",
    "# select the first, second and third rows from the surveys variable\n",
    "surveys_df[0:3]\n",
    "# select the first 5 rows (rows 0,1,2,3,4)\n",
    "surveys_df[:5]\n",
    "# select the last element in the list\n",
    "surveys_df[-1:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reassign values within subsets of our DataFrame. But before we do that, let's make a \n",
    "copy of our DataFrame so as not to modify our original imported data. \n",
    "\n",
    "```python\n",
    "# copy the surveys dataframe so we don't modify the original DataFrame\n",
    "surveys_copy = surveys_df\n",
    "\n",
    "# set the first three rows of data in the DataFrame to 0\n",
    "surveys_copy[0:3] = 0\n",
    "```\n",
    "\n",
    "Next, try the following code: \n",
    "\n",
    "```python\n",
    "surveys_copy.head()\n",
    "surveys_df.head()\n",
    "```\n",
    "What is the difference between the two data frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the surveys dataframe so we don't modify the original DataFrame\n",
    "surveys_copy = surveys_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first three rows of data in copied DataFrame to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the copy of the data\n",
    "surveys_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the original data\n",
    "surveys_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencing Objects vs Copying Objects in Python\n",
    "\n",
    "We might have thought that we were creating a fresh copy of the `surveys_df` objects when we \n",
    "used the code `surveys_copy = surveys_df`. However the statement  y = x doesn’t create a copy of our DataFrame. \n",
    "It creates a new variable y that refers to the **same** object x refers to. This means that there is only one object \n",
    "(the DataFrame), and both x and y refer to it. So when we assign the first 3 columns the value of 0 using the \n",
    "`surveys_copy` DataFrame, the `surveys_df` DataFrame is modified too. To create a fresh copy of the `surveys_df`\n",
    "DataFrame we use the syntax y=x.copy(). But before we have to read the surveys_df again because the current version contains the unintentional changes made to the first 3 columns.\n",
    "\n",
    "```python\n",
    "surveys_df = pd.read_csv(\"data/surveys.csv\")\n",
    "surveys_copy= surveys_df.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data frame since we just broke it\n",
    "surveys_df = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a copy the \"right\" way\n",
    "surveys_copy = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first three rows of data in copied DataFrame to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the copy of the data\n",
    "surveys_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the original data\n",
    "surveys_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python Pandas\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions\n",
    "using either label or integer-based indexing.\n",
    "\n",
    "- `loc`: indexing via *labels* (which can be integers)\n",
    "- `iloc`: indexing via *integers*\n",
    "\n",
    "\n",
    "![dataframe_indexing](https://vrzkj25a871bpq7t1ugcgmn9-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/pandas-dataframe-has-indexes.png)\n",
    "\n",
    "To select a subset of rows AND columns from our DataFrame, we can use the `iloc`\n",
    "method. For example, we can select month, day and year (columns 2, 3 and 4 if we\n",
    "start counting at 1), like this:\n",
    "\n",
    "```python\n",
    "surveys_df.iloc[0:3, 1:4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_df.iloc[0:3, 1:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from 0:3. This yielded 3 rows of data. When you\n",
    "ask for 0:3, you are actually telling python to start at index 0 and select rows\n",
    "0, 1, 2 **up to but not including 3**.\n",
    "\n",
    "\n",
    "Let's next explore some other ways to index and select subsets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns for rows of index values 0 and 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "surveys_df.loc[0:4, 'plot': 'wgt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you run the code below?\n",
    "surveys_df.loc[[0, 10, 45549], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Labels must be found in the DataFrame or you will get a `KeyError`. The\n",
    "start bound and the stop bound are **included**.  When using `loc`, integers\n",
    "*can* also be used, but they refer to the **index label** and not the position. Thus\n",
    "when you use `loc`, and select 1:4, you will get a different result than using\n",
    "`iloc` to select rows 1:4.\n",
    "\n",
    "We can also select a specific data value according to the specific row and\n",
    "column location within the data frame using the `iloc` function:\n",
    "`dat.iloc[row,column]`.\n",
    "\n",
    "\n",
    "```python\n",
    "surveys_df.iloc[2,6]\n",
    "```\n",
    "\n",
    "which gives **output**\n",
    "\n",
    "```\n",
    "'F'\n",
    "```\n",
    "\n",
    "Remember that Python indexing begins at 0. So, the index location [2, 6] selects\n",
    "the element that is 3 rows down and 7 columns over in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Activities\n",
    "\n",
    "1. What happens when you type:\n",
    "    1. surveys_df[0:3]\n",
    "    2. surveys_df[:5]\n",
    "    3. surveys_df[-1:]\n",
    "\n",
    "2. What happens when you call:\n",
    "    1. `surveys_df.iloc[0:4, 1:4]`\n",
    "    2. `surveys_df.loc[0:4, 1:4]`\n",
    "    3. How are the two commands different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Masks\n",
    "\n",
    "A mask can be useful to locate where a particular subset of values exist or\n",
    "don't exist - for example,  NaN, or \"Not a Number\" values. To understand masks,\n",
    "we also need to understand `BOOLEAN` objects in python.\n",
    "\n",
    "Boolean values include `true` or `false`. So for example\n",
    "\n",
    "```python\n",
    "# set x to 5\n",
    "x = 5\n",
    "# what does the code below return?\n",
    "x > 5\n",
    "# how about this?\n",
    "x == 5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ask python what the value of `x > 5` is, we get `False`. This is because x\n",
    "is not greater than 5 it is equal to 5. To create a boolean mask, you first create the\n",
    "True / False criteria (e.g. values > 5 = True). Python will then assess each\n",
    "value in the object to determine whether the value meets the criteria (True) or\n",
    "not (False). Python creates an output object that is the same shape as\n",
    "the original object, but with a True or False value for each index location.\n",
    "\n",
    "\n",
    "### Logical evaluators\n",
    "You can use the syntax below when querying data from a DataFrame. Experiment\n",
    "with selecting various subsets of the \"surveys\" data.\n",
    "\n",
    "* Equals: `==`\n",
    "* Not equals: `!=`\n",
    "* Greater than, less than: `>` or `<`\n",
    "* Greater than or equal to `>=`\n",
    "* Less than or equal to `<=`\n",
    "\n",
    "Let's try this out.\n",
    "\n",
    "Let's identify all locations in the survey data that have\n",
    "null (missing or NaN) data values. We can use the `isnull` method to do this.\n",
    "Each cell with a null value will be assigned a value of  `True` in the new\n",
    "boolean object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(surveys_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values,  we can use \n",
    "the mask as an index to subset our data as follows:\n",
    "\n",
    "```python\n",
    "#To select just the rows with NaN values, we can use the .any method\n",
    "surveys_df[pd.isnull(surveys_df).any(axis=1)]\n",
    "```\n",
    "\n",
    "Note that there are many null or NaN values in the `wgt` column of our DataFrame.\n",
    "We will explore different ways of dealing with these in Lesson 03.\n",
    "\n",
    "We can run `isnull` on a particular column too. What does the code below do?\n",
    "\n",
    "```python\n",
    "# what does this do?\n",
    "empty_weights = surveys_df[pd.isnull(surveys_df).any(axis=1)]['wgt']\n",
    "```\n",
    "\n",
    "Let's take a minute to look at the statement above. \n",
    "\n",
    "We are using the Boolean object as an index. \n",
    "We are asking python to select rows that have a `NaN` value\n",
    "for weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the empty_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can also select a subset of our data using criteria. For example, we can\n",
    "select all rows that have a year value of 2002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can select all rows that do not contain the year 2002.\n",
    "surveys_df[?]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can define sets of criteria as well:\n",
    "# eg, year 1980 or more but less than or equal to 1985\n",
    "surveys_df[?]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activities\n",
    "\n",
    "1. Select a subset of rows in the `surveys_df` DataFrame that contain data from\n",
    "   the year 1999 and that contain weight values less than or equal to 8. How\n",
    "   many rows did you end up with? What did your neighbor get?\n",
    "2. You can use the `isin` command in python to query a DataFrame based upon a\n",
    "   list of values as follows:\n",
    "   `surveys_df[surveys_df['species'].isin([listGoesHere])]`. Use the `isin` function\n",
    "   to find all plots that contain particular species in\n",
    "   the surveys DataFrame. How many records contain these values?\n",
    "3. Experiment with other queries. Create a query that finds all rows with a weight value > or equal to 0.\n",
    "4. The `~` symbol in Python can be used to return the OPPOSITE of the selection that you specify in python. \n",
    "It is equivalent to **is not in**. Write a query that selects all rows that are NOT equal to 'M' or 'F' in the surveys\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatinating\n",
    "\n",
    "We can use the `concat` function in Pandas to append either columns or rows from\n",
    "one DataFrame to another.  Let's grab two subsets of our data to see how this\n",
    "works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in first 10 lines of surveys table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the last 10 rows (minus the last one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis. `axis=0` tells\n",
    "Pandas to stack the second DataFrame under the first one. It will automatically\n",
    "detect whether the column names are the same and will stack accordingly.\n",
    "`axis=1` will stack the columns in the second DataFrame to the RIGHT of the\n",
    "first DataFrame. To stack the data vertically, we need to make sure we have the\n",
    "same columns and associated column format in both datasets. When we stack\n",
    "horizonally, we want to make sure what we are doing makes sense (ie the data are\n",
    "related in some way).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the DataFrames on top of each other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the DataFrames side by side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there are now two `wgt` columns\n",
    "# How does the following behave?\n",
    "horizontal_stack['wgt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything unusual about the `vertical_stack`?\n",
    "\n",
    "The row indexes for the two data frames `survey_sub` and `survey_sub_last10`\n",
    "have been repeated. We can reindex the new dataframe using the `reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV\n",
    "\n",
    "We can use the `to_csv` command to do export a DataFrame in CSV format. Note that the code\n",
    "below will by default save the data into the current working directory. We can\n",
    "save it to a different folder by adding the foldername and a slash to the file\n",
    "`vertical_stack.to_csv('foldername/out.csv')`.\n",
    "\n",
    "```python\n",
    "# Write DataFrame to CSV \n",
    "vertical_stack.to_csv('out.csv')\n",
    "```\n",
    "\n",
    "Check out your working directory to make sure the CSV wrote out properly, and\n",
    "that you can open it! If you want, try to bring it back into python to make sure\n",
    "it imports properly.\n",
    "\n",
    "```python\t\n",
    "# let's read our output back into python and make sure all looks good\n",
    "new_output = pd.read_csv('out.csv', keep_default_na=False, na_values=[\"\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the vertical_stack to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check that the file exists"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
